# TCN

Temporal convolutional network æ—¶é—´å·ç§¯ç½‘ç»œ

ä¸‰ä¸ªé‡è¦æ¦‚å¿µï¼š

* Causal Convï¼šå› æœå·ç§¯
* Dilated Convï¼šç©ºæ´å·ç§¯
* Residual blockï¼šæ®‹å­˜å—

ç ”ç©¶æ¨¡å‹ï¼šsequence model æ—¶åºæ¨¡å‹



ç ”ç©¶ç‚¹ï¼šthe memory retention characteristics of recurrent networks è®°å¿†ä¿ç•™ç‰¹æ€§

TCNä¼˜åŠ¿åœºæ™¯ï¼š where a long history is required.



TCNçš„ä¸¤ä¸ªé‡è¦ç‰¹å¾ï¼š

* è¾“å…¥è¾“å‡ºé•¿åº¦ç›¸åŒ
* ä¸å—æœªæ¥æ¸—é€ï¼Œåªæ¥å—å†å²çš„å½±å“

å®ç°æ–¹å¼ï¼šTCN = 1D FCN + causal convolutions

ç¼ºç‚¹ï¼šä¸ºäº†æ„Ÿå—æœ‰æ•ˆçš„ã€è¶…é•¿çš„å†å²é•¿åº¦ï¼Œæˆ‘ä»¬éœ€è¦æ›´æ·±çš„ç½‘ç»œç»“æ„æˆ–ä¸€ä¸ªè¶…å¤§çš„è¿‡æ»¤å™¨ï¼ˆfliterï¼‰ã€‚

è§£å†³æ–¹æ³•ï¼šç©ºæ´å·ç§¯â€”â€”æŒ‡æ•°çº§åˆ«å¢å¤§æ„Ÿå—é‡ â¬†ï¸ï¼ˆä¸éœ€è¦é‚£ä¹ˆæ·±çš„ç½‘ç»œï¼‰ï¼›æ®‹å­˜å—é¿å…deeper networkçš„é—®é¢˜ ï¼ˆè§£å†³è¿‡æ·±ç½‘è·¯çš„é—®é¢˜ï¼‰â¬‡ï¸ï¼›



1 D FCNï¼š

> Each hidden layer is the same length as the input layer, and zero padding of length (kernel size âˆ’ 1) is added to keep subsequent layers the same length as previous ones. 
>
> æ¯ä¸ªéšè—å±‚ä¸è¾“å…¥å±‚çš„é•¿åº¦ç›¸åŒï¼Œå¹¶ä¸”æ·»åŠ é•¿åº¦çš„é›¶å¡«å……ï¼ˆå†…æ ¸å¤§å° - 1ï¼‰ä»¥ä¿æŒåç»­å±‚ä¸å‰ä¸€å±‚çš„é•¿åº¦ç›¸åŒã€‚



causal convolutionï¼š

> convolutions where an output at time t is convolved only with elements from time t and earlier in the previous layer.
>
> å› æœå·ç§¯ï¼Œå…¶ä¸­æ—¶é—´ t çš„è¾“å‡ºä»…ä¸æ—¶é—´ t å’Œå‰ä¸€å±‚ä¸­æ›´æ—©çš„å…ƒç´ è¿›è¡Œå·ç§¯ã€‚



residual blockï¼š<a href="https://towardsdatascience.com/residual-blocks-building-blocks-of-resnet-fd90ca15d6ec">ResNet</a>

> Since a TCNâ€™s receptive field depends on the network depth **n** as well as filter size **k** and dilation factor **d**, stabilization of deeper and larger TCNs becomes important.

> Our residual block is overall trying to learn the true output, *H(x). If* you look closely at the image above, you will realize that since we have an identity connection coming from *x*, the layers are actually trying to learn the residual, *R(x)*. So to summarize, the layers in a traditional network are learning the true output (*H(x)*), whereas the layers in a residual network are learning the residual (*R(x)*). Hence, the name: *Residual Block*.



deep networkçš„é—®é¢˜ï¼š

* æ¢¯åº¦çˆ†ç‚¸/æ¶ˆå¤±
* è¿‡æ‹Ÿåˆ



### TCNsä¼˜ç¼ºç‚¹

Advantagesï¼š

* Parallelism: å¹¶è¡Œ

* Flexible receptive field size: çµæ´»çš„æ„Ÿå—é‡å¤§å°
* **Stable gradients**: ç¨³å®šçš„ææ¢¯åº¦ã€Œé¿å…äº†æ¢¯åº¦çˆ†ç‚¸çš„é—®é¢˜ã€
* Low memory requirement for training: è®­ç»ƒæ—¶éœ€è¦æ›´å°‘çš„å†…å­˜
* Variable length inputs: å¯å˜é•¿åº¦è¾“å…¥ã€Œé€šè¿‡æ»‘åŠ¨1Då·ç§¯æ ¸æ¥æ¥å—ä»»æ„é•¿åº¦çš„è¾“å…¥ã€

Disadvantagesï¼š

* Data storage during evaluationï¼šæµ‹è¯•é—´æ–­éœ€è¦è·Ÿå¤šçš„å†…å­˜ï¼ˆéœ€è¦æœ‰æ•ˆå†å²é•¿åº¦çš„æ•°æ®ï¼‰
* **Potential parameter change for a transfer of domain**ï¼šä¸åŒåœºæ™¯é€‚é…çš„ã€Œå†å²é•¿åº¦ã€ä¸åŒï¼Œéœ€è¦è°ƒæ•´ã€Œkã€ã€ã€Œdã€ä»¥æ›´æ”¹æ„Ÿå—é‡ï¼ˆï¼Ÿä¸æ˜¯è¶Šå¤§è¶Šå¥½ï¼‰



### è®ºæ–‡ç»“æ„ç´¢å¼•

1. Introduction
2. Background
3. TCN ä»‹ç»ä¸»è¦æ–¹æ³•ï¼šæ—¶é—´å·ç§¯ç½‘ç»œ
   1. æ—¶åºæ¨¡å‹
   2. Causal Convolutionsï¼šå› æœå·ç§¯
   3. Dilated Convolutionsï¼šç©ºæ´å·ç§¯
   4. Residual Connectionsï¼š æ®‹å­˜è¿æ¥ é¿å…æ¢¯åº¦æ¶ˆå¤±
4. Discusion: æ€»ç»“
5. 



å¾…æŸ¥åè¯ï¼š

* å·ç§¯ç½‘ç»œ
  * channel_numï¼šæƒ³åˆ°RGBçš„ä¾‹å­
  * ä½œä¸ºç‰¹å¾æå–çš„å·¥å…·

* kernel
* filter
* ReLU æ•´æµçº¿æ€§å•å…ƒã€Œéçº¿æ€§å±‚ã€
* WeightNorm å½’ä¸€åŒ–



é“¾æ¥ï¼š

* <a href="https://blog.csdn.net/qq_36269513/article/details/80420363">fcn(å…¨å·ç§¯ç¥ç»ç½‘ç»œ)å’Œcnn(å·ç§¯ç¥ç»ç½‘ç»œ)çš„åŒºåˆ«</a>
* <a href="https://www.zhihu.com/question/54149221">ç©ºæ´å·ç§¯çš„ç†è§£</a>
* <a href="https://blog.csdn.net/program_developer/article/details/80958716">æ„Ÿå—é‡çš„ç†è§£</a>
* <a href="https://blog.csdn.net/qq_27586341/article/details/90751794">TCNæ¦‚è§ˆ</a>
* <a href="https://blog.csdn.net/qq_27825451/article/details/90550890">torch.nn.module</a>
* <a href="https://blog.csdn.net/qq_34107425/article/details/105522916">å·ç§¯è§’åº¦ç†è§£</a>





æ±‡æŠ¥ï¼š

ä»‹ç»TCN

è§„åˆ’ï¼šä¸€å‘¨æŒæ¡è¿™ä¸ªç½‘ç»œï¼ˆè¿˜åŸéƒ¨åˆ†å®éªŒï¼‰ï¼ˆåŒæ­¥éƒä¸–æ‰¬è°ƒç ”åº”ç”¨åœºæ™¯ï¼‰ã€Œå…œåº•åœºæ™¯ï¼šåŸºæœ¬çš„è·Ÿè½¦æ¨¡å‹ã€



å¯æ“ä½œç‚¹ï¼š





### å¯¹port_musicçš„è°ƒç ”

* å·ç§¯ï¼ˆConvolutionï¼‰ã€å¡«å……ï¼ˆPaddingï¼‰ã€Œé¿å…è¾¹ç¼˜ä¿¡æ¯æŸå¤±ã€ã€æ­¥é•¿(Stride)ã€Œå‹ç¼©ç»†è…»ã€ã€‚

* filterï¼šå·ç§¯æ ¸çš„é›†åˆ

* Channelsï¼šCNNæ¨¡å‹çš„å®½åº¦ï¼Œéš§é“çš„æ•°é‡ã€‚ï¼ˆRGBï¼‰

> **æŸä¸€å±‚æ»¤æ³¢å™¨çš„é€šé“æ•° = ä¸Šä¸€å±‚ç‰¹å¾å›¾çš„é€šé“æ•°ã€‚**å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œæˆ‘ä»¬è¾“å…¥ä¸€å¼  ![[å…¬å¼]](https://www.zhihu.com/equation?tex=6%5Ctimes6%5Ctimes3) çš„RGBå›¾ç‰‡ï¼Œé‚£ä¹ˆæ»¤æ³¢å™¨ï¼ˆ ![[å…¬å¼]](https://www.zhihu.com/equation?tex=3%5Ctimes3%5Ctimes3) ï¼‰ä¹Ÿè¦æœ‰ä¸‰ä¸ªé€šé“ã€‚
>
> **æŸä¸€å±‚è¾“å‡ºç‰¹å¾å›¾çš„é€šé“æ•° = å½“å‰å±‚æ»¤æ³¢å™¨çš„ä¸ªæ•°ã€‚**å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œå½“åªæœ‰ä¸€ä¸ªfilteræ—¶ï¼Œè¾“å‡ºç‰¹å¾å›¾ï¼ˆ ![[å…¬å¼]](https://www.zhihu.com/equation?tex=4%5Ctimes4) ï¼‰çš„é€šé“æ•°ä¸º1ï¼›å½“æœ‰2ä¸ªfilteræ—¶ï¼Œè¾“å‡ºç‰¹å¾å›¾ï¼ˆ![[å…¬å¼]](https://www.zhihu.com/equation?tex=4%5Ctimes4%5Ctimes2) )çš„é€šé“æ•°ä¸º2ã€‚
>
> <img src="https://pic3.zhimg.com/80/v2-fc70463d7f82f7268ee23b7235515f4a_1440w.jpg" alt="img" style="zoom:67%;" />

* æ¿€æ´»å‡½æ•°ä½œç”¨ï¼šéçº¿æ€§å¤„ç†ã€‚

* forwardï¼šå®šä¹‰æ¨¡å‹å‰å‘ä¼ æ’­æ–¹æ³•ã€‚
* å®éªŒä¸ºäº†å¾—åˆ°è¶…å‚kernel_sizeã€num_channels(nhidã€levels)



### åº”ç”¨åœºæ™¯æ–¹æ¡ˆ/å®éªŒæ–¹æ¡ˆåˆ¶å®š

#### æ€»ä½“æ€è·¯

1. TCNå•ä¸€åœºæ™¯é¢„æµ‹ä¼˜åŒ–ã€Œæå‡x, yçš„å‡†ç¡®æ€§ã€ï¼ˆå›¾æ ‡åˆ†æï¼šlossæ›²çº¿ã€é¢„æµ‹æ›²çº¿ï¼‰
   1. å•æ­¥é¢„æµ‹
   2. å¤šæ­¥é¢„æµ‹
2. æ¨ªå‘æ¯”è¾ƒï¼š
   1. åŒæ ·çš„åœºæ™¯ï¼ˆchannel_num/input_size/ç‰¹å¾æ•°é‡ã€æ—¶é—´æ­¥é•¿ï¼‰çš„æƒ…å†µä¸‹ï¼Œä¸åŒæ¨¡å‹ä¹‹é—´çš„æ•ˆæœæ¯”è¾ƒï¼ˆé¢„æµ‹æ›²çº¿ï¼‰
   2. ä¸åŠçš„åœ°æ–¹skipè‡³step1è¿›ä¸€æ­¥æé«˜æ¨¡å‹ç²¾åº¦
3. è®ºæ–‡äº§å‡º



#### åˆ†å·¥

æ•°æ®å¤„ç†ã€ã€Œç½‘ç»œç»“æ„è®¾è®¡ã€å®éªŒè°ƒå‚ã€ã€matplotlibæ•°æ®å¯è§†åŒ–ã€è®ºæ–‡ç»“æ„è°ƒç ”ä¸åå“ºå®éªŒæ­¥éª¤



#### Plan I

ç®€å•è·Ÿè½¦åœºæ™¯ï¼š

**INIT** ã€Œbitch, channel_num, timestepã€

è¾“å…¥ç»´åº¦ï¼šã€Œ32, 4, 80ã€

* 32ï¼šbitchå¤§å°
* 4ï¼šchannel_num 4ä¸ªç»´åº¦çš„å…¥å‚ç‰¹å¾ï¼ŒåŒ…å«ç›®æ ‡ğŸš—(Target)åœ¨æŸä¸€æ—¶åˆ»çš„x, yå’Œè·Ÿé©°ğŸš—(Subject)åœ¨æŸä¸€æ—¶åˆ»çš„x, y
* 80ï¼štimestepæ—¶é—´æ­¥é•¿

è¾“å‡ºç»´åº¦ï¼šã€Œ32, 2, 1ã€

* 2ï¼šä¸‹ä¸€æ—¶åˆ»è·Ÿé©°ğŸš—çš„x, y

å¯è°ƒæ•´å‚æ•°ï¼š

* æ•°æ®å±‚é¢
  * channel_numçš„æ•°é‡ï¼Œé€‰å–æ›´å¤šç‰¹å¾ã€ŒåŠ é€Ÿåº¦ã€é€Ÿåº¦ã€ä¸ƒè½¦...ã€
  * timestepï¼Œæå‡/å‡å°‘æ—¶é—´æ­¥é•¿ï¼Œæå‡é¢„æµ‹å‡†ç¡®æ€§/æé€Ÿæ¨¡å‹æ”¶æ•›
* ç½‘ç»œç»“æ„å±‚é¢
  * kernel_size å·ç§¯æ ¸å¤§å°
  * nhids éšè—å±‚ç»†èƒæ•°
  * level å±‚æ•°
  * epoch è½®æ•°
  * æ¿€æ´»å‡½æ•°ã€æŸå¤±å‡½æ•°ã€ä¼˜åŒ–å‡½æ•°ã€éçº¿æ€§ã€è¿‡æ‹Ÿåˆ...



both in terms of convergence and in final accuracy on the task.

æ”¶æ•›æ€§ï¼šlossä¸‹é™çš„é€Ÿåº¦ã€æœ€ç»ˆçš„å‡†ç¡®æ€§ã€åœ¨ä¸åŒæ—¶é—´æ­¥é•¿ä¸‹çš„é€‚åº”æ€§ï¼ˆlonger memoryä¸‹æ›´å…·ä¼˜åŠ¿ã€ã€Œchannel_numå‚æ•°æ•°é‡è¿™ä¸ªåº”è¯¥å’Œå…·ä½“çš„åœºæ™¯æœ‰å…³

### å®éªŒè®°å½•

### TCN

| knize | level | nhid | epoch | ç»“æœ                                                         |
| ----- | ----- | ---- | ----- | ------------------------------------------------------------ |
| 4     | 4     | 32   | 10    | Test set: Average loss: 2.328249<br /><img src="/Users/bytedance/Library/Application Support/typora-user-images/image-20220409210635079.png" alt="image-20220409210635079" style="zoom:50%;" /><img src="/Users/bytedance/Library/Application Support/typora-user-images/image-20220409210643228.png" alt="image-20220409210643228" style="zoom:50%;" /><img src="/Users/bytedance/Library/Application Support/typora-user-images/image-20220409210702541.png" alt="image-20220409210702541" style="zoom:50%;" /> |
| 2     | 4     | 32   | 10    | Test set: Average loss: 27.643204<br /><img src="/Users/bytedance/Library/Application Support/typora-user-images/image-20220409000409118.png" alt="image-20220409000409118" style="zoom:50%;" /><img src="/Users/bytedance/Library/Application Support/typora-user-images/image-20220409000420777.png" alt="image-20220409000420777" style="zoom:50%;" /><img src="/Users/bytedance/Library/Application Support/typora-user-images/image-20220409000458623.png" alt="image-20220409000458623" style="zoom:50%;" /> |
| 8     | 4     | 32   | 10    | <img src="/Users/bytedance/Library/Application Support/typora-user-images/image-20220408152925016.png" alt="image-20220408152925016" style="zoom:50%;" /><br /><img src="/Users/bytedance/Library/Application Support/typora-user-images/image-20220408152941686.png" alt="image-20220408152941686" style="zoom:50%;" /><img src="/Users/bytedance/Library/Application Support/typora-user-images/image-20220408152951686.png" alt="image-20220408152951686" style="zoom:50%;" /><img src="/Users/bytedance/Library/Application Support/typora-user-images/image-20220408153034456.png" alt="image-20220408153034456" style="zoom:50%;" /> |
| 6     | 4     | 32   | 10    | <img src="/Users/bytedance/Library/Application Support/typora-user-images/image-20220408162426817.png" alt="image-20220408162426817" style="zoom:50%;" /><br /><br /><img src="/Users/bytedance/Library/Application Support/typora-user-images/image-20220408162436237.png" alt="image-20220408162436237" style="zoom:50%;" /><img src="/Users/bytedance/Library/Application Support/typora-user-images/image-20220408162448895.png" alt="image-20220408162448895" style="zoom:50%;" /><img src="/Users/bytedance/Library/Application Support/typora-user-images/image-20220408162519240.png" alt="image-20220408162519240" style="zoom:50%;" /> |
| 4     | 8     | 32   | 10    | Test set: Average loss: 43.825653<br /><img src="/Users/bytedance/Library/Application Support/typora-user-images/image-20220408183851142.png" alt="image-20220408183851142" style="zoom:50%;" /><img src="/Users/bytedance/Library/Application Support/typora-user-images/image-20220408183942857.png" alt="image-20220408183942857" style="zoom:50%;" /><img src="/Users/bytedance/Library/Application Support/typora-user-images/image-20220408184058501.png" alt="image-20220408184058501" style="zoom:50%;" /> |
| 4     | 4     | 64   | 10    | Test set: Average loss: 35.814930<br /><img src="/Users/bytedance/Library/Application Support/typora-user-images/image-20220408222433462.png" alt="image-20220408222433462" style="zoom:50%;" /><img src="/Users/bytedance/Library/Application Support/typora-user-images/image-20220408222449278.png" alt="image-20220408222449278" style="zoom:50%;" /><img src="/Users/bytedance/Library/Application Support/typora-user-images/image-20220408222552234.png" alt="image-20220408222552234" style="zoom:50%;" /> |
|       |       |      |       |                                                              |
|       |       |      |       |                                                              |

### LSTM

|      |      |      |      |      |
| ---- | ---- | ---- | ---- | ---- |
|      |      |      |      |      |
|      |      |      |      |      |
|      |      |      |      |      |
|      |      |      |      |      |
|      |      |      |      |      |

æ•°æ®é‡æ–°ç­›é€‰ç®—æ³•ï¼š

* æ—¶é—´ï¼ˆframeIDï¼‰ä¸Yçš„æ’åº
* æ‰¾ã€æ„å»ºè·Ÿè½¦å¯¹ï¼ˆå‰åä¸¤è½¦åœ¨åŒä¸€è½¦é“ä¸”æ£€ä¸¾å°äº100ï¼‰ï¼Œä¿ç•™å‰åè½¦xã€yã€aã€vï¼Œæ—¶é—´ï¼Œè½¦è¾†IDï¼Œè½¦é“
* è·Ÿè½¦å¯¹ä¾æ®ç›®æ ‡è½¦IDå’Œæ—¶é—´ã€è·Ÿè½¦IDæ’åºï¼Œé€šè¿‡è¿‡æ—¶é—´å’ŒIDçš„æ–¹å¼æ„é€ æ ‡ç­¾



* 80æ—¶é—´æ­¥é•¿ã€i-80è·¯æ®µçš„å„ä¸ªç½‘ç»œæ¯”è¾ƒï¼šåŸºæœ¬çš„TCNä¼˜åŠ¿
* 60ã€100æ—¶é—´æ­¥é•¿ä¸‹ã€i-80è·¯æ®µå„ä¸ªç½‘ç»œæ¯”è¾ƒï¼šä¸åŒæ—¶é—´æ­¥é•¿ä¸‹ç½‘ç»œçš„æ”¶æ•›æ€§
* 80æ—¶é—´æ­¥é•¿ã€å…¶ä»–è·¯æ®µçš„å„ä¸ªç½‘è·¯æ¯”è¾ƒï¼šæ³›åŒ–æ€§
